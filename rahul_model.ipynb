{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, stop, course_history = 32, 4, []\n",
    "log_dir = './logs/'+time.ctime().replace(' ', '_').replace(':', '.')\n",
    "os.mkdir(log_dir)\n",
    "print('To check in on tensorboard, copy and paste following line to cmd')\n",
    "print('tensorboard --logdir={0}'.format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.045\n",
    "    lrate = initial_lrate * 0.94 ** np.floor(epoch/2)# Learning rate decay: decay of rate 0.94 every 2 epochs\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "if not os.path.exists('./data/models/'):\n",
    "    os.mkdir('./data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any([True if 'preped_data_cifar' in file_name else False for file_name in os.listdir('./data/')]):\n",
    "    with np.load(file='./data/preped_data_cifar.npz') as big_load:\n",
    "        X = big_load['train_arr']\n",
    "        x_test = big_load['test_arr']\n",
    "        y = big_load['y_fine']\n",
    "        y_test = big_load['y_fine_test'] \n",
    "        y_c = big_load['y_c_train']\n",
    "        y_c_test = big_load['y_c_test']\n",
    "        fine2coarse=big_load['fine2coarse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=.1, random_state=0)\n",
    "_, _, y_c_train, y_c_val = train_test_split(\n",
    "    X, y_c, test_size=.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = kr.layers.Input(shape=(128, 128, 3), name='image_input')\n",
    "x = kr.layers.Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n",
    "x = kr.layers.BatchNormalization(name='block1_conv1_bn')(x)\n",
    "x = kr.layers.Activation('relu', name='block1_conv1_act')(x)\n",
    "x = kr.layers.Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
    "x = kr.layers.BatchNormalization(name='block1_conv2_bn')(x)\n",
    "x = kr.layers.Activation('relu', name='block1_conv2_act')(x)\n",
    "residual = kr.layers.Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = kr.layers.BatchNormalization()(residual)\n",
    "x = kr.layers.SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n",
    "x = kr.layers.BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "x = kr.layers.Activation('relu', name='block2_sepconv2_act')(x)\n",
    "x = kr.layers.SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n",
    "x = kr.layers.BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "x = kr.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n",
    "x = kr.layers.add([x, residual])\n",
    "residual = kr.layers.Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = kr.layers.BatchNormalization()(residual)\n",
    "x = kr.layers.Activation('relu', name='block3_sepconv1_act')(x)\n",
    "x = kr.layers.SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n",
    "x = kr.layers.BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "x = kr.layers.Activation('relu', name='block3_sepconv2_act')(x)\n",
    "x = kr.layers.SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n",
    "x = kr.layers.BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "x = kr.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n",
    "x = kr.layers.add([x, residual])\n",
    "x = kr.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = kr.layers.Dense(2, activation='softmax', name='predictions')(x)\n",
    "model = kr.Model(img_input, x, name='shared_layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_callbacks(log_dir, run_name):\n",
    "    log_dir = log_dir+os.sep+run_name\n",
    "    if os.path.exists(log_dir):\n",
    "        log_dir += '_00'\n",
    "        while os.path.exists(log_dir):\n",
    "            _log_dir = log_dir[:-2]\n",
    "            _log_dir += log_dir[-2]+str(int(log_dir[-1])+1)\\\n",
    "                if int(log_dir[-1])+1 < 9 else str(int(log_dir[-2])+1)+'0'\n",
    "            log_dir = _log_dir\n",
    "            del _log_dir\n",
    "    os.mkdir(log_dir)\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=log_dir),\n",
    "        kr.callbacks.LearningRateScheduler(step_decay),\n",
    "        kr.callbacks.History()]\n",
    "    return callbacks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=kr.optimizers.SGD(lr=0.045, momentum=0.9, decay=0),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.4681 - acc: 0.8076 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2480 - val_loss: 0.4196 - val_acc: 0.8240 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2204\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.3881 - acc: 0.8311 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2321 - val_loss: 0.4492 - val_acc: 0.8340 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2367\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.3655 - acc: 0.8493 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2192 - val_loss: 0.5989 - val_acc: 0.8160 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2079\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 25s 5ms/step - loss: 0.3476 - acc: 0.8547 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2093 - val_loss: 0.4282 - val_acc: 0.8320 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66e9f63588>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_c_train, batch_size=batch_size, initial_epoch=0, \n",
    "          validation_data=(x_val, y_c_val), epochs=stop, callbacks=gen_callbacks(log_dir, 'base_block'))\n",
    "x_shared_preds = model.predict(x_train, verbose=1, batch_size=32)\n",
    "x_shared_preds_val = model.predict(x_val, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.Model(inputs=img_input, outputs=model.layers[-3].output)\n",
    "x_shared_out = model.predict(x_train, verbose=1, batch_size=32)\n",
    "x_shared_out_val = model.predict(x_val, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath='data/models/tony_net/shared_layers_weights')\n",
    "with open('data/models/tony_net/shared_layers.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "del model\n",
    "kr.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fine(shared_out, shared_preds):\n",
    "    samples = shared_preds.shape[0]\n",
    "    _classes = shared_preds.shape[-1]\n",
    "    fine = np.concatenate(\n",
    "        (shared_out,\n",
    "         shared_preds.reshape(samples, 1, 1, _classes) \\\n",
    "         * np.ones(shape=(shared_out.shape[0:3]+(_classes,))),),\n",
    "        axis=3)\n",
    "    return fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 2 (4500, 2)\n",
      "500 2 (500, 2)\n"
     ]
    }
   ],
   "source": [
    "fine_x = generate_fine(x_shared_out, x_shared_preds)\n",
    "fine_x_val = generate_fine(x_shared_out_val, x_shared_preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_input = kr.layers.Input(shape=(fine_x.shape[1:]), name='fine_input')\n",
    "residual = kr.layers.Conv2D(728, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(fine_input)\n",
    "residual = kr.layers.BatchNormalization()(residual)\n",
    "x = kr.layers.Activation('relu', name='block4_sepconv1_act')(fine_input)\n",
    "x = kr.layers.SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n",
    "x = kr.layers.BatchNormalization(name='block4_sepconv1_bn')(x)\n",
    "x = kr.layers.Activation('relu', name='block4_sepconv2_act')(x)\n",
    "x = kr.layers.SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n",
    "x = kr.layers.BatchNormalization(name='block4_sepconv2_bn')(x)\n",
    "x = kr.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n",
    "x = kr.layers.add([x, residual])\n",
    "for i in range(3):\n",
    "    residual = x\n",
    "    prefix = 'block' + str(i + 5)\n",
    "    x = kr.layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "    x = kr.layers.SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n",
    "    x = kr.layers.BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
    "    x = kr.layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "    x = kr.layers.SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n",
    "    x = kr.layers.BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
    "    x = kr.layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "    x = kr.layers.SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n",
    "    x = kr.layers.BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
    "    x = kr.layers.add([x, residual])\n",
    "x = kr.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = kr.layers.Dense(5, activation='softmax', name='predictions')(x)\n",
    "model = kr.Model(fine_input, x, name='fine_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_cat = 2\n",
    "start, end = 5 * (course_cat - 1), 5 * course_cat\n",
    "label = np.argmax(y_train, axis=1)\n",
    "label_val = np.argmax(y_val, axis=1)\n",
    "find_ind = np.where(np.logical_and(label>=start, label<end))[0]\n",
    "find_ind_val = np.where(np.logical_and(label_val>=start, label_val<end))[0]\n",
    "del course_cat, label, label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2252, 16, 16, 258), (2252, 5), (248, 16, 16, 258), (248, 5))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_x[find_ind].shape, y_train[find_ind][:,start:end].shape, \\\n",
    "fine_x_val[find_ind_val].shape, y_val[find_ind_val][:,start:end].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=kr.optimizers.SGD(lr=0.045, momentum=0.9, decay=0),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2252 samples, validate on 248 samples\n",
      "Epoch 1/39\n",
      "2252/2252 [==============================] - 10s 5ms/step - loss: 5.8746 - acc: 0.2966 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2867 - val_loss: 5.8343 - val_acc: 0.3226 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2769\n",
      "Epoch 2/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 3.3861 - acc: 0.3215 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2822 - val_loss: 3.5080 - val_acc: 0.2742 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2906\n",
      "Epoch 3/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 2.5121 - acc: 0.3570 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2768 - val_loss: 2.1580 - val_acc: 0.3831 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2747\n",
      "Epoch 4/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 2.4944 - acc: 0.3628 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2726 - val_loss: 3.3016 - val_acc: 0.3871 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2570\n",
      "Epoch 5/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 2.2224 - acc: 0.3646 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2717 - val_loss: 2.1403 - val_acc: 0.3508 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2863\n",
      "Epoch 6/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.9412 - acc: 0.3779 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2701 - val_loss: 2.1891 - val_acc: 0.2581 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2924\n",
      "Epoch 7/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 2.0237 - acc: 0.4036 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2664 - val_loss: 2.6469 - val_acc: 0.3427 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2717\n",
      "Epoch 8/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.9338 - acc: 0.4005 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2648 - val_loss: 1.5417 - val_acc: 0.3992 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2693\n",
      "Epoch 9/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.8906 - acc: 0.3979 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2666 - val_loss: 2.3958 - val_acc: 0.3065 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2907\n",
      "Epoch 10/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.8338 - acc: 0.4183 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2627 - val_loss: 2.8879 - val_acc: 0.3952 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2603\n",
      "Epoch 11/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 2.2264 - acc: 0.3739 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2677 - val_loss: 2.6800 - val_acc: 0.3911 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2630\n",
      "Epoch 12/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.9176 - acc: 0.4076 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2657 - val_loss: 1.6982 - val_acc: 0.4153 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2644\n",
      "Epoch 13/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.7982 - acc: 0.4361 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2616 - val_loss: 1.6202 - val_acc: 0.3952 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2731\n",
      "Epoch 14/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.7577 - acc: 0.4170 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2624 - val_loss: 1.8878 - val_acc: 0.4153 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2732\n",
      "Epoch 15/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.8026 - acc: 0.4245 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2610 - val_loss: 1.6260 - val_acc: 0.3710 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2754\n",
      "Epoch 16/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.7659 - acc: 0.4245 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2646 - val_loss: 1.5990 - val_acc: 0.4597 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2681\n",
      "Epoch 17/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.6597 - acc: 0.4485 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2546 - val_loss: 1.6651 - val_acc: 0.4032 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2698\n",
      "Epoch 18/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.6514 - acc: 0.4565 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2570 - val_loss: 1.6684 - val_acc: 0.3387 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2853\n",
      "Epoch 19/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.5811 - acc: 0.4498 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2539 - val_loss: 1.5236 - val_acc: 0.4315 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2707\n",
      "Epoch 20/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.3643 - acc: 0.4658 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2553 - val_loss: 1.4885 - val_acc: 0.4395 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2660\n",
      "Epoch 21/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.2746 - acc: 0.4818 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2489 - val_loss: 1.4433 - val_acc: 0.4395 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2582\n",
      "Epoch 22/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.2626 - acc: 0.4996 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2483 - val_loss: 1.4355 - val_acc: 0.4435 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2663\n",
      "Epoch 23/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.2520 - acc: 0.4925 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2479 - val_loss: 1.5024 - val_acc: 0.4476 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2657\n",
      "Epoch 24/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.2157 - acc: 0.5151 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2447 - val_loss: 1.3519 - val_acc: 0.4637 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2494\n",
      "Epoch 25/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1908 - acc: 0.5235 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2402 - val_loss: 1.4212 - val_acc: 0.4435 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2471\n",
      "Epoch 26/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.2019 - acc: 0.5115 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2412 - val_loss: 1.3010 - val_acc: 0.4718 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2504\n",
      "Epoch 27/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1863 - acc: 0.5213 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2390 - val_loss: 1.4209 - val_acc: 0.5323 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2500\n",
      "Epoch 28/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1704 - acc: 0.5306 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2378 - val_loss: 1.2790 - val_acc: 0.5403 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2364\n",
      "Epoch 29/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1583 - acc: 0.5413 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2342 - val_loss: 1.3841 - val_acc: 0.4556 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2506\n",
      "Epoch 30/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1375 - acc: 0.5373 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2285 - val_loss: 1.3922 - val_acc: 0.4839 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2519\n",
      "Epoch 31/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1328 - acc: 0.5346 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2319 - val_loss: 1.3887 - val_acc: 0.5242 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2422\n",
      "Epoch 32/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1167 - acc: 0.5506 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2273 - val_loss: 1.2736 - val_acc: 0.5323 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2313\n",
      "Epoch 33/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.1178 - acc: 0.5560 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2269 - val_loss: 1.4038 - val_acc: 0.5242 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2353\n",
      "Epoch 34/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0952 - acc: 0.5617 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2239 - val_loss: 1.2716 - val_acc: 0.5202 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2379\n",
      "Epoch 35/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0811 - acc: 0.5675 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2217 - val_loss: 1.4836 - val_acc: 0.4435 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2370\n",
      "Epoch 36/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0584 - acc: 0.5657 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2195 - val_loss: 1.3960 - val_acc: 0.4516 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2495\n",
      "Epoch 37/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0650 - acc: 0.5826 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2185 - val_loss: 1.4436 - val_acc: 0.4919 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2304\n",
      "Epoch 38/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0326 - acc: 0.5906 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2140 - val_loss: 1.5077 - val_acc: 0.4677 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2389\n",
      "Epoch 39/39\n",
      "2252/2252 [==============================] - 9s 4ms/step - loss: 1.0295 - acc: 0.5959 - top_k_categorical_accuracy: 1.0000 - mean_absolute_error: 0.2110 - val_loss: 1.2897 - val_acc: 0.5282 - val_top_k_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f667c241e48>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(fine_x[find_ind], y_train[find_ind][:,start:end], batch_size=batch_size, initial_epoch=0, \n",
    "          validation_data=(fine_x_val[find_ind_val], y_val[find_ind_val][:,start:end]), epochs=39, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath='data/models/tony_net/fine_1_weights')\n",
    "with open('data/models/tony_net/fine_1.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "del model\n",
    "kr.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
